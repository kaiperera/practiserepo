---
title: "chapter10"
output: html_document
date: "2025-02-05"
---
#### Exploratory data analysis
### Variation
defined = tendency of variable's values to change from measurement to measurement
measure any continuous variable 2x = 2 different results
Each measuremetn icnludes small amount of error varying between elements
Variables also vary if measuring across different subjects/ different times
Each variable has different pattern of variation- insight into how it varies between measurements on same observation and across observations

visualizing the distribution of weights (carat) of ~54,000 diamonds from the diamonds dataset. Since carat is a numerical variable,  can use a histogram:
```{r VARIATION CARAT HISTOGRAM}
ggplot(diamonds, aes(x = carat)) +
  geom_histogram(binwidth = 0.5)
```
## Typical Values
Both bar hcarts and histograms = tall bars -> more common values of a variable - places w no bars suggest values not seen in data
To turn this information into useful questions, look for anything unexpected:
 ``` 1. which values more common and y?
 2. which values rare? Does this match expectations?
  3. any unusual patterns? what might explain them? 
  ```
Look at distribution for carat for smaller diamonds:
```{r CARAT SMALLER DIAMONDS}
smaller <- diamonds |> 
  filter(carat < 3) 

ggplot(diamonds, aes(x = carat)) +
  geom_histogram(binwidth = 0.01)
```
Potential Questions:
why are there more diamonds at whole carats (eg. 1, 2) and common fractions of caracts (0.5) 
why are there more diamonds slightly to the right of each larger peak than to the left 

visualisations can also reveal clusters - suggests subgroups exist in data. To understand subgroups, need to ask:
```How are observations in each subgroup similar to each other?
How are observations in separate clusters different to each other?
How can clusters be explained / described?
Why might cluster appearance seem misleading? 
```
some questions can be answered by data alone whereas others need domain expertise
explore relationships between variables

## Unusual Values
Outliers can be data entry errors, extreme values observed within data OR could suggest important new discoveries.
When there is a lot of data, outliers sometimes hard to see in histogram
eg) take the distribution of the y variable from the diamonds dataset. The only evidence of outliers is the unusually wide limits on the x-axis.
```{r DIAMOND OUTLIER}
ggplot(diamonds, aes(x = y)) + 
  geom_histogram(binwidth = 0.5)
```
so many observations in common bins that rare bind v short  - hard to see them 
to make it easier to see unusual values, zoom small values of y axis with coord_cartesian():
```{r ZOOM}
ggplot(diamonds, aes(x = y)) +
  geom_histogram(binwidth = 0.5) +
  coord_cartesian(ylim = c(0,50))
```
coord_cartesian also has xlim() in case need to zoom into x axis.
ggplot2 also has xlim and ylim functions but work differently - throw data away outside the limits
Allows us to see there are 3 unusual values: 0, ~30 and ~60- pluck out with dplyr:
```{r OUTLIERS PLUCKED OUT}
unusual <- diamonds |> 
  filter(y < 3 | y > 20) |> 
  select(price, x, y, z) |>
  arrange(y)
unusual
```
y variable measures 1 of 3 dimensions for diamonds in mm - diamonds cant have a width of 0 so these values must be wrong 
By doing EDA, discovered missing data coded for as 0 that woulds have been found if only searching for N/As - might  want to recode these values as N/As to prevent misleading calculations
Might also suspect 32mma and 59mm are incorrect- massive but cheap
good to repeat analysis with and without outliers - if have minimal effect on result and can't figure out y they r there, safe to omit BUT if substantial effect, shouldnt drop without justification

##Exercises
1. Explore the distribution of each of the x, y, and z variables in diamonds. What do you learn? Think about a diamond and how you might decide which dimension is the length, width, and depth.
```{r 1}
ggplot(diamonds, aes(x = x)) +
  geom_histogram(binwidth = 0.5) +
  coord_cartesian(ylim = c(0, 50))

ggplot(diamonds, aes(x = z)) +
   geom_histogram(binwidth = 0.5) +
  coord_cartesian(ylim = c(0, 50))

ggplot(diamonds, aes(x = y)) +
  geom_histogram(binwidth = 0.5) +
  coord_cartesian(ylim = c(0,50))
```
x = length, y = width, z = depth
the distribution of x primarily ranges from ~3 - ~10mm, with some outliers at the 0 mark. the distribution of z is <10, with values between ~1- ~8mm. There is an outlier at ~35mm and another at the 0mm mark
The distributions for the z and y variables seem very similar, whilst x is noticeably different with regards to distribution. 

2. Explore the distribution of price. Do you discover anything unusual or surprising? (Hint: Carefully think about the binwidth and make sure you try a wide range of values.)
```{r 2}
ggplot(diamonds, aes(x = price)) +
  geom_histogram(binwidth = 850)

ggplot(diamonds, aes(x = price)) +
  geom_histogram(binwidth = 850) +
coord_cartesian(xlim = c(0,5000)) 
  

```
It seems as thought the majority of diamonds surveyed tend to be prices below 5,000, especially within the ~500 - ~1200 range. As price increases, the frequency decreases.This makes sense as diamonds percieved as more desirable tend to be rare, relating to carat, clarity and/or size, and thus are more expensive. 

3. How many diamonds are 0.99 carat? How many are 1 carat? What do you think is the cause of the difference?
```{r 3}
ggplot(diamonds, aes(x = carat)) +
  geom_histogram() +
  coord_cartesian(xlim = c(0.8,1))
```
there is no observable difference, both 0.99 and 1 carat diamonds both have a count of ~7500

4. Compare and contrast coord_cartesian() vs. xlim() or ylim() when zooming in on a histogram. What happens if you leave binwidth unset? What happens if you try and zoom so only half a bar shows?
xlim = zooms in using the x axis - in this case can only see values in the range of 0.8 and 1 with regards to carat
ylim = same as xlim but on y axis
leaving binwidth empty means ggplot automatically determines a default bin based on the range and distribution of the given data

### More Unusual Values
If encountered unusual data and simply want to move on, have 2 options:
  \1. drop entire row of strange values:
```{r DROP}
diamonds2 <- diamonds |> 
  filter(between(y, 3, 20))
```
not ideal - 1 invalid value doesnt imply all other observations from this value r also invalid
  \2. Replace unusual values with missing values - easiest way is to mutate and replace variable with modified copy - can use if_else() function to replace unusualy values with N/A:
```{r REPLACE}
diamonds2 <- diamonds |> 
  mutate(y = if_else(y < 3 | y > 20, NA, y))
```
not obvious where missing points should be plotted so ggplot removes them but has a warning message:
```{r WARNING}
ggplot(diamonds2, aes(x = x, y = y)) + 
  geom_point()
```

to suppress warning, na.rm = TRUE:
```{r SUPPRESS WARNING}
ggplot(diamonds2, aes(x = x, y = y)) + 
  geom_point(na.rm = TRUE)
```

May want to understand what makes observations with missing values different to those w recorded values
eg) nycflights13::flights -> missing values in dep_time variable indicates flight was cancelled
might want to compare scheduled departure times for cancelled and non-cancelled times - can do by making new variable, using is.na() to check if dep_time() is missing:
```{r COMPARE DEP_TIME FOR CANCELLED AND NON CANCELLED }
nycflights13::flights |> 
  mutate(
    cancelled = is.na(dep_time),   #is.na() is a function in R that checks if a value is missing (NA). It returns TRUE if a value is missing and FALSE if it is no
    sched_hour = sched_dep_time %/% 100,
    sched_min = sched_dep_time %% 100,
    sched_dep_time = sched_hour + (sched_min / 60)
  ) |> 
  ggplot(aes(x = sched_dep_time)) + 
  geom_freqpoly(aes(colour = cancelled), binwidth = 1/4)
```
plot not great as more non-cancelled flights than cancelled flights

##Exercises
1. What happens to missing values in a histogram? What happens to missing values in a bar chart? Why is there a difference in how missing values are handled in histograms and bar charts?:
Histograms = N/As automatically ignored
Bar Chart = N/As grouped together in separate category
Histograms group continuous numeric data into bins and missing values can't be grouped into any bin. Bar charts count categorical data and so missing values are treated like an additional group

2. What does na.rm = TRUE do in mean() and sum()?
Mean = computes mean, ignoring N/As
Sum = computes sum, ignoring N/As

3. Recreate the frequency plot of scheduled_dep_time colored by whether the flight was cancelled or not. Also facet by the cancelled variable. Experiment with different values of the scales variable in the faceting function to mitigate the effect of more non-cancelled flights than cancelled flights.
```{r 3}
nycflights13::flights |> 
  mutate(
    cancelled = is.na(dep_time),
    sched_hour = sched_dep_time %/% 100,
    sched_min = sched_dep_time %% 100,
    sched_dep_time = sched_hour + (sched_min / 60)
  ) |> 
  ggplot(aes(x = sched_dep_time, colour = cancelled)) + 
  geom_freqpoly(binwidth = 1/4) +
  facet_wrap(~cancelled)
```

### Covariation
Describes behaviour between variables- tendency for values of 2 + variables to vary together in a related way
best way to spot covariation is to visualise relationship between 2+ variables

##Categorical and Numerical variables:
diamond price varies with quality (measured by cut):
```{r CATEGORICAL/NUMERICAL}
ggplot(diamonds, aes(x = price)) +
  geom_freqpoly(aes(colour = cut), binwidth = 500, linewidth = 0.75)
```
default appearance not useful here as height (determined by overall count) differs a lot across cuts - hard to see differences in distribution shapes
To make easier comparison, need to swap what is displayed on y axis - instead of count, will display density = count standardised so area under frequency polygon is 1:
```{r COUNT -> DENSITY}
ggplot(diamonds, aes(x = price, y = after_stat(density))) + 
  geom_freqpoly(aes(color = cut), binwidth = 500, linewidth = 0.75)
```
mapping density to y BUT density not a variable in dataset so calculating it w the after_stat() argument
According to plot, lowest quality diamonds have highest price - frequency polygons can be hard to interpret
visually simpler plot for exploring this would be a side - by - side boxplot:
```{r SIDE BY SIDE BP}
ggplot(diamonds, aes(x = cut, y = price)) +
  geom_boxplot()
```
Less info about distribution BUT boxplots more compact = easier comparison 
Supports counter-intuitive idea that lower quality diamonds are more expensive on average
Cut is an ordered variable (fair worse than good, good worse than v.good etc)- most categorical variables aren't so ordered 
reorder them  via fct_reorder():
```{r REORDER CATEGORICAL VARIABLE}
ggplot(mpg, aes(x = class, y = hwy)) +
  geom_boxplot()

#to make it easier to see:
ggplot(mpg, aes(x = fct_reorder(class, hwy, median), y = hwy)) +
  geom_boxplot()
```
If have long variable names, geom_boxplot better  if flipped 90 degrees- can do by swapping x and y aesthetic mappings:
```{r FLIP FOR LONG VARIABLE NAMES}
ggplot(mpg, aes(x = hwy, y = fct_reorder(class, hwy, median))) +
  geom_boxplot()
```
# Exercises
1. Use what you’ve learned to improve the visualization of the departure times of cancelled vs. non-cancelled flights.
```{r 1}
nycflights13::flights |> 
  mutate(
    cancelled = factor(is.na(dep_time), labels = c("Not Cancelled", "Cancelled")), ## had to change into factor, original logical TRUE / FALSE argument
    sched_hour = sched_dep_time %/% 100,
    sched_min = sched_dep_time %% 100,
    sched_dep_time = sched_hour + (sched_min / 60)
  ) |> 
 ggplot(aes(x = cancelled, y = sched_dep_time)) + 
  geom_boxplot() +
  labs(
    title = "Scheduled Departure Time Distribution by Flight Cancellation",
    x = "Flight Status",
    y = "Scheduled Departure Time (Hours)"
  ) +
  theme_minimal()
```
2. Based on EDA, what variable in the diamonds dataset appears to be most important for predicting the price of a diamond? How is that variable correlated with cut? Why does the combination of those two relationships lead to lower quality diamonds being more expensive?
```{r 2}
ggplot(diamonds, aes(x = price, y = clarity)) +
  geom_boxplot() 

ggplot(diamonds, aes(x = price, y = color)) +
  geom_boxplot() 

ggplot(diamonds, aes(x = cut, y = color)) +
  geom_count()

ggplot(diamonds, aes(x = color, y = carat)) +
  geom_boxplot()
```
clarity - high clarity not equal to high price
colour = good colour not equal to high price
carat = not really 

It seems as though the worse colour is, the more expensive the diamond is. In terms of correlating to cut, a lot of the J rated diamonds are also classed as "ideal", making them more expensive. Additionally, the  J rated diamonds have a higher average carat compared to other colours, adding to their increased price. 


3. Instead of exchanging the x and y variables, add coord_flip() as a new layer to the vertical boxplot to create a horizontal one. How does this compare to exchanging the variables?
```{r 3}
ggplot(mpg, aes(x = hwy, y = fct_reorder(class, hwy, median))) +
  geom_boxplot()


ggplot(mpg, aes(x = fct_reorder(class, hwy, median), y = hwy)) +
  geom_boxplot() +
  coord_flip()
```
does the same thing

4. One problem with boxplots is that they were developed in an era of much smaller datasets and tend to display a prohibitively large number of “outlying values”. One approach to remedy this problem is the letter value plot. Install the lvplot package, and try using geom_lv() to display the distribution of price vs. cut. What do you learn? How do you interpret the plots?
```{r 4}
ggplot(diamonds, aes(x = cut, y = price)) +
  geom_lv()
```

5. Create a visualization of diamond prices vs. a categorical variable from the diamonds dataset using geom_violin(), then a faceted geom_histogram(), then a colored geom_freqpoly(), and then a colored geom_density(). Compare and contrast the four plots. What are the pros and cons of each method of visualizing the distribution of a numerical variable based on the levels of a categorical variable?
```{r 5}
#geom violin
ggplot(diamonds, aes(x = price, y = cut)) +
  geom_violin()

#faceted geom histogram
ggplot(diamonds, aes(x = price)) +
  geom_histogram() +
  facet_wrap(~cut)

# coloured geom_freqpoly
ggplot(diamonds, aes(x = price)) +
  geom_freqpoly(aes(colour = cut))


#coloured geom_density
ggplot(diamonds, aes(x = price, fill = cut)) +
  geom_density(alpha = 0.5)  # alpha controls transparency
```

6.If you have a small dataset, it’s sometimes useful to use geom_jitter() to avoid overplotting to more easily see the relationship between a continuous and categorical variable. The ggbeeswarm package provides a number of methods similar to geom_jitter(). List them and briefly describe what each one does.
geom_beeswarm() = makes beeswarm plot where points spaced to minimize overlap
geom_quasirandom() = distributed points in a quasi random way - useful for a more organic scatter
geom_violinswarm() = mix of violin and beeswarm plots - combines violin plot with beeswarm of individual points
geom_jitterwidth() = adds horizontal jitter to reduce overlap on categorical data
geom_beeswarm_horizontal() = horziontal beeswarm plot for better visualisation of horizontal data


## 2 Categorical Variables:
to visualise covariation between categorical variables, nned to count no. of observations for each combination of levels in those variables 
one way to do this is geom_count:
```{r GEOM_COUNT}
ggplot(diamonds, aes(x = cut, y = color)) +
  geom_count()
```
Size of each circle on plot correlates to how many observations occurred at each combination of values
covariation will appear as strong correlation between specific x values and specific y values

Another way = computing counts w dpylr:
```{r COMPUTING COUNTS WITH DPYLR}
diamonds |> 
  count(color, cut)
```

The visualise w geom_tile and fill:
```{r GEOM TILE AND FILL}
diamonds |> 
  count(color, cut) |>  
  ggplot(aes(x = color, y = cut)) +
  geom_tile(aes(fill = n))
```
if categorical datas are unordered, might want to use seriation package to simultaneously reorder rows and columns - clearly reveal any patterns 
Larger plots = heatmaply package, which creates interactive plots

# Exercises:
1. How could you rescale the count dataset above to more clearly show the distribution of cut within color, or color within cut?
```{r 1}
ggplot(diamonds, aes(x = cut, y = color)) +
  geom_count() +  # Size represents the count
  scale_size_continuous(range = c(3, 10)) +  # Adjust size range for better visibility
  labs(title = "Distribution of Cut within Color",
       x = "Cut",
       y = "Color") +
  theme_minimal()



```
Rescaling can either be done by adjusting the size of the counts to reflect the distribution or by normalizing the counts to get proportions of each category combination.

2. What different data insights do you get with a segmented bar chart if color is mapped to the x aesthetic and cut is mapped to the fill aesthetic? Calculate the counts that fall into each of the segments.
```{r 2}
ggplot(diamonds, aes(x = color, fill = cut)) +
  geom_bar(position = "fill")
ggplot(diamonds, aes(x = color, fill = cut)) +
  geom_bar(position = "dodge")
```

3.Use geom_tile() together with dplyr to explore how average flight departure delays vary by destination and month of year. What makes the plot difficult to read? How could you improve it?
```{r 3}
flight_delays <- flights |> 
  filter(!is.na(dep_delay)) |> 
  group_by(dest, month) |> 
  summarise(avg_dep_delay = mean(dep_delay, na.rm = TRUE), .groups = "drop")  #process flight data

# create map
ggplot(flight_delays, aes(x = month, y = dest, fill = avg_dep_delay)) +
  geom_tile() +
  scale_fill_gradient(low = "blue", high = "red") +
  labs(title = "Average Departure Delay by Destination and Month",
       x = "month",
       y = "destination",
       fill = "average delay (mins") +
  theme_minimal() +
  scale_y_discrete(guide = guide_axis(n.dodge = 2)) # spreads out labels
```

this plot is hard to read due to the large number of destinations, maxing the y axis cluttered. Although scale_y_discrete was used, it separated out the labels such that it is hard to determine which tile correlates to which y axis variable. Additionally, the small tile size makes it hard to read and the colour scale may be hard to interpret


## 2 Numerical Variables
scatter plot via geom_point - can see covariation as patter in points 
eg) positive relationship between carat size and diamond price:
```{r POSITIVE RELATIONSHIP CARAT AND PRICE}
ggplot(diamonds, aes(x = carat, y = price)) +
  geom_point()
```
scatterplots become less usedful as dataset size groqa - points overplot and pile up - hard to judge differences in density / spot trends
one way to fix is alpha aesthetic- transparency:
```{r ALPHA FOR TRANSPARENCY}
ggplot(diamonds, aes(x = carat, y = price)) + 
  geom_point(alpha = 1 / 100)
```
transparency can be challenginf for large datasets
can also use bin- used in 1D for histograms and freqpoly but here use geom_bin2d and geom_hex for 2D
these divide coordinates into 2d bins and use a fill colour to display how many points fall within each bin
bin2d creates rectangular bins vs hex makes hexagonal bins- need to install hexbin package
```{r BIN2D AND HEXBIN}
ggplot(diamonds, aes(x = carat, y = price)) +
  geom_bin2d()

ggplot(diamonds, aes(x = carat, y = price)) +
  geom_hex()
```
can also bin 1 continuous variable so it acts like a categorical variable - can then use a technique for visualising categorical-continuous combo 
eg) bin carat and then display boxplot for each group
```{r COMBO}
ggplot(diamonds, aes(x = carat, y = price)) +
  geom_boxplot(aes(group = cut_width(carat, 0.1)))
```
cut_width(x, width) = divides x bins of specified width
by default, boxplots look roughly the same except number of outliers regardless of how many observations there are - hard to tell that each boxplot summarises different number of points
one way to show that width of boxplot is proportional to number of points is varwidth = TRUE

# Exercises
1. Instead of summarizing the conditional distribution with a boxplot, you could use a frequency polygon. What do you need to consider when using cut_width() vs. cut_number()? How does that impact a visualization of the 2d distribution of carat and price?
```{r 1}
# cut_width
ggplot(diamonds, aes(x = carat, colour = cut_width(carat, 0.2))) +
  geom_freqpoly(stat = "bin", binwidth = 0.2) +
  labs(title = "frequency polygon of carat",
       x = "carat",
       y = "count")

#cut_number
ggplot(diamonds, aes(x = carat, colour = cut_number(carat, 10)))+  # 10 obs per bin
  geom_freqpoly(stat = "bin", bins = 10) +
  labs(title = "frequency polygon of carat",
       x = "carat",
       y = "count")


```


cut_width = creates bins of equal width eg) every 0.5 carat- useful when wanting consistent interval size across range BUT may lead to uneven sample sizes per bin if data unevenly distributed
Bins equally spaced along x axis and can reveal trends over fixed interval - may result in some bins having very few data points eg) rare high carat diamonds

cut_number = creates bins w equal numbers of observations per bin - ensures each bin has ~ same amount of values BUT bin width varies so interpretation can be hard- useful if data highly skewed
bins have equal number of diamonds - if diamonds mostly lower carat, bins for larger diamonds will be wider - can make visualisation hard to interpret due to inconsistent bin widths 

2.Visualize the distribution of carat, partitioned by price
```{r 2 histogram}
# create price bins via cut_number to divide in 5 bins of equal obs
diamond2 <- diamonds |> 
  mutate(price_bin = cut_number(price, 5))

#plot carat by price
ggplot(diamond2, aes(x = carat)) +
  geom_histogram(binwidth = 0.1, fill = "blue", colour = "green") +
  facet_wrap(~price_bin, scales = "free_y") +
  labs(title = "Distribution of carat by price",
       x = "carat",
       y = "count")
#Facet Scaling: Use scales = "free_y" to handle varying counts in each price bin.
```
```{r 2 boxplot}
ggplot(diamond2, aes(x = price_bin, y = carat)) +
  geom_boxplot() +
  labs(title = "boxplot of carat by price bin",
       x = "price bin",
       y = "carat")
```
```{r 2 density plot}
ggplot(diamond2, aes(x = carat, fill = price_bin)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~price_bin) +
  labs(title = "density plot of carat by price",
       x = "carat",
       y = "density")
```

3. How does the price distribution of very large diamonds compare to small diamonds? Is it as you expect, or does it surprise you?
```{r 3}
diamondsize <- diamonds |> 
  mutate(diamond_size = ifelse(carat < 1, "small", "large"))

ggplot(diamondsize, aes(x = price, fill = diamond_size)) +
  geom_density(alpha = 0.5) +
  labs(title = "price distribution of small and large diamonds",
       x = "price",
       y = "density")
```
this makes sense, as the larger, rarer diamonds seem to be more expensive than the smaller and more abundant diamonds

4. Combine two of the techniques you’ve learned to visualize the combined distribution of cut, carat, and price.
```{r 4}
ggplot(diamonds, aes(x = carat, y= price)) +
  geom_boxplot(aes(group = cut_width(carat, 0.1))) +
  facet_wrap(~cut)

```

5. Two dimensional plots reveal outliers that are not visible in one dimensional plots. For example, some points in the following plot have an unusual combination of x and y values, which makes the points outliers even though their x and y values appear normal when examined separately. Why is a scatterplot a better display than a binned plot for this case
```{r 5}
diamonds |> 
  filter(x >= 4) |> 
  ggplot(aes(x = x, y = y)) +
  geom_point() +
  coord_cartesian(xlim = c(4, 11), ylim = c(4, 11))
```
scatterplots are better in this case due to the identification of outliers. This is because ach data point's exact position is shown and a relationshio between observations is easier to ascertain. Binned plots aggregate data, obscuring true positioning/distirbution and therefore masking outliers 

6. Instead of creating boxes of equal width with cut_width(), we could create boxes that contain roughly equal number of points with cut_number(). What are the advantages and disadvantages of this approach?
```{r 6}
ggplot(diamonds, aes(x = carat, y = price)) + 
  geom_boxplot(aes(group = cut_number(carat, 20)))
```
cut_number advantages:
```
each bin has equal number of data points - each bin equally represented - usefull when data is skewed
highly skewed data - bins w ewaul width can be dominated by larger/smaller values (depending on how its skewed), making interpretation difficult
prevents sparse bins when there are outliers / extreme values
```
cut_number disadvantages:
```
the inconsistent bin widths can make it harder to interpret distribution as the bin sizes aren't uniform - varying widths can distort analysis (smaller bins = more detailed information but potentially more noise vs larger = more sensitive to changes in data)
hard to interpret scale of data- not good if goal is to see how data behaves across consistent intervals
misleading visualisations - unequal binwidths can make it harder to see trends / patterns
```

### Patterns and Models
patterns in data provide clues about relationships eg)revealing covariation
variation creates uncertainty, covariation reduces it
if 2 variables covary, can use values of 1 variable to make better predictions about values of second
if covariation due to causal relationship, can use value of 1 variable to control value of second

models = tools for extracting patterns out of data
eg) hard to understand relationship between cut and price - cut + carat and carat + price all tightly related 
possible to use model to remove strong relationship between carat and price
following code fits model that predicts price from carat - then computes resideuals (difference between predicted value and actual value)
residuals give us view of diamond price once effect of carat been removed
instead of using raw values of price and carat, log transform them first - fit a model to log-transformed values - exponentiate residuals to put them back in scales of raw prices
```{r MODEL}
# install.packages('tidymodels')
diamonds <- diamonds |>
  mutate(
    log_price = log(price),
    log_carat = log(carat)
  )

diamonds_fit <- linear_reg() |>
  fit(log_price ~ log_carat, data = diamonds)

diamonds_aug <- augment(diamonds_fit, new_data = diamonds) |>
  mutate(.resid = exp(.resid))

ggplot(diamonds_aug, aes(x = carat, y = .resid)) + 
  geom_point()
```
once removed strong relationship between price and carat, can see what would be expected in relationship between cut and price - relative to size, better quality diamonds more expensive
```{r MODELS 2}
ggplot(diamonds_aug, aes(x = cut, y = .resid)) + 
  geom_boxplot()
```

